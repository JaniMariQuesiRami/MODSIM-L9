{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. (Pruebas para comparar dos distribuciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Distribuciones: Prueba de Hipótesis\n",
    "\n",
    "En este laboratorio, exploraremos cómo comparar dos distribuciones utilizando pruebas de hipótesis en Python. Examinaremos dos pruebas estadísticas populares: la **prueba de Chi-Cuadrado** y la **prueba de Kolmogorov-Smirnov**. Ambas pruebas son útiles para evaluar si dos conjuntos de datos siguen distribuciones similares. Usaremos las bibliotecas `scipy.stats` y `statsmodels` para realizar estas pruebas en Python.\n",
    "\n",
    "### 1. Prueba de Chi-Cuadrado\n",
    "\n",
    "La prueba de Chi-Cuadrado es una prueba no paramétrica que permite evaluar si hay diferencias significativas entre las frecuencias observadas y esperadas en una muestra de datos categóricos. Esta prueba es útil para comparar distribuciones en datos discretos.\n",
    "\n",
    "#### ¿Cómo Funciona?\n",
    "La prueba calcula un estadístico `chi^2` que mide la distancia entre las frecuencias observadas y las frecuencias esperadas bajo la hipótesis nula. Si el valor `chi^2` es suficientemente alto, podemos rechazar la hipótesis nula de que las distribuciones son iguales.\n",
    "\n",
    "#### Aplicación en Python\n",
    "\n",
    "Para aplicar la prueba de Chi-Cuadrado en Python, utilizamos la función `chi2_contingency` de `scipy.stats`. Este método toma una tabla de contingencia (matriz de frecuencias) como entrada y devuelve el valor `chi^2` y el valor-p asociado, entre otros valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadístico Chi-Cuadrado: 0.6800857042324314\n",
      "p-valor: 0.7117398225515237\n",
      "Grados de libertad: 2\n",
      "Frecuencias esperadas:\n",
      " [[ 8.80733945 19.26605505 31.9266055 ]\n",
      " [ 7.19266055 15.73394495 26.0733945 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Definimos nuestras muestras\n",
    "observed_data = np.array([[10, 20, 30], [6, 15, 28]])  # Ejemplo de frecuencias observadas\n",
    "\n",
    "# Realizamos la prueba de Chi-Cuadrado\n",
    "chi2, p, dof, expected = chi2_contingency(observed_data)\n",
    "\n",
    "print(\"Estadístico Chi-Cuadrado:\", chi2)\n",
    "print(\"p-valor:\", p)\n",
    "print(\"Grados de libertad:\", dof)\n",
    "print(\"Frecuencias esperadas:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación**: Si el valor-p es menor que el nivel de significancia elegido (por ejemplo, 0.05), podemos rechazar la hipótesis nula, indicando que las distribuciones de las muestras son significativamente diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prueba de Kolmogorov-Smirnov\n",
    "\n",
    "La prueba de Kolmogorov-Smirnov (KS) es una prueba no paramétrica para comparar dos distribuciones continuas. Es particularmente útil para muestras pequeñas y no requiere que las muestras sigan una distribución específica (es decir, es una prueba de bondad de ajuste general).\n",
    "\n",
    "### ¿Cómo Funciona?\n",
    "La prueba de KS calcula la distancia máxima entre las funciones de distribución acumulativa de las dos muestras. Si esta distancia es suficientemente grande, podemos rechazar la hipótesis nula de que ambas muestras provienen de la misma distribución.\n",
    "\n",
    "### Aplicación en Python\n",
    "\n",
    "Para realizar la prueba de Kolmogorov-Smirnov en Python, usamos la función `ks_2samp` de `scipy.stats`, que toma dos muestras como argumentos y devuelve el estadístico KS y el valor-p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadístico KS: 0.15\n",
      "p-valor: 0.21117008625127576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Definimos nuestras muestras\n",
    "sample1 = np.random.normal(0, 1, 100)\n",
    "sample2 = np.random.normal(0, 1, 100)\n",
    "\n",
    "# Realizamos la prueba de Kolmogorov-Smirnov\n",
    "ks_statistic, p_value = ks_2samp(sample1, sample2)\n",
    "\n",
    "print(\"Estadístico KS:\", ks_statistic)\n",
    "print(\"p-valor:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación**: Al igual que con la prueba de Chi-Cuadrado, si el valor-p es menor que el nivel de significancia, podemos rechazar la hipótesis nula y concluir que las distribuciones de las muestras son diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Ambas pruebas, Chi-Cuadrado y Kolmogorov-Smirnov, son útiles para comparar distribuciones, aunque aplican a diferentes tipos de datos (categóricos y continuos, respectivamente). En Python, estas pruebas se pueden realizar fácilmente utilizando `scipy.stats`, permitiéndonos evaluar la similitud entre distribuciones en pocos pasos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
